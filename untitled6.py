# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nnOPAcBk5jLiENvZ8M9ePbcjJ3vikCOo
"""

!pip install -q transformers torch gradio accelerate bitsandbytes

# IBM Granite 3.2 2B Multi-Tool AI Application - Google Colab Ready
# One-line installation and error-free execution

# Single installation command - run this first!
!pip install -q transformers torch gradio accelerate bitsandbytes

import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import warnings
warnings.filterwarnings("ignore")

# Initialize the model and tokenizer with error handling
class GraniteAI:
    def __init__(self):
        self.model_name = "ibm-granite/granite-3.0-2b-instruct"
        self.model = None
        self.tokenizer = None
        self.load_model()

    def load_model(self):
        try:
            print("üîÑ Loading IBM Granite model... This may take 2-3 minutes.")

            # Quantization config for memory efficiency
            quantization_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.float16,
                bnb_4bit_use_double_quant=True,
                bnb_4bit_quant_type="nf4"
            )

            # Load tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )

            # Load model with quantization
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                quantization_config=quantization_config,
                torch_dtype=torch.float16,
                trust_remote_code=True,
                device_map="auto"
            )

            # Set pad token
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
                self.tokenizer.pad_token_id = self.tokenizer.eos_token_id

            print("‚úÖ Model loaded successfully!")
            return True

        except Exception as e:
            print(f"‚ùå Error loading model: {str(e)}")
            print("üîÑ Trying fallback model...")
            try:
                # Fallback to a working alternative
                self.model_name = "microsoft/DialoGPT-medium"
                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
                self.model = AutoModelForCausalLM.from_pretrained(
                    self.model_name,
                    torch_dtype=torch.float16,
                    device_map="auto"
                )
                if self.tokenizer.pad_token is None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                print("‚úÖ Fallback model loaded successfully!")
                return True
            except Exception as e2:
                print(f"‚ùå Fallback failed: {str(e2)}")
                return False

    def generate_response(self, prompt, max_new_tokens=300, temperature=0.7, top_p=0.9):
        """Generate response with comprehensive error handling"""
        if self.model is None or self.tokenizer is None:
            return "‚ùå Model not loaded. Please restart and try again."

        try:
            # Format prompt properly
            formatted_prompt = f"Human: {prompt}\n\nAssistant: "

            # Tokenize input
            inputs = self.tokenizer.encode(
                formatted_prompt,
                return_tensors="pt",
                truncation=True,
                max_length=512
            )

            # Move to same device as model
            if torch.cuda.is_available():
                inputs = inputs.cuda()

            # Generate response
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.1,
                    no_repeat_ngram_size=3
                )

            # Decode response
            full_response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)

            # Extract only the new generated text
            response = full_response[len(formatted_prompt):].strip()

            # Clean up response
            if not response:
                response = "I apologize, but I couldn't generate a proper response. Please try rephrasing your request."

            return response

        except Exception as e:
            return f"‚ùå Generation error: {str(e)}. Please try again with a shorter prompt."

# Initialize the AI model globally
print("üöÄ Initializing AI system...")
ai = GraniteAI()

# Tool Functions with error handling
def safe_generate(prompt_template, **kwargs):
    """Wrapper for safe generation with error handling"""
    try:
        prompt = prompt_template.format(**kwargs)
        return ai.generate_response(prompt, max_new_tokens=400)
    except Exception as e:
        return f"‚ùå Error: {str(e)}. Please check your inputs and try again."

# 1. ü™Ñ Story Wizard
def story_wizard(genre, character, setting, plot_twist, length):
    if not all([genre, character, setting, plot_twist]):
        return "‚ö†Ô∏è Please fill in all fields to generate a story."

    length_map = {"Short": "2-3 paragraphs", "Medium": "4-5 paragraphs", "Long": "6-8 paragraphs"}

    prompt = f"""Write an engaging {genre} story with these elements:
- Main Character: {character}
- Setting: {setting}
- Plot Twist: {plot_twist}
- Length: {length_map[length]}

Create a captivating narrative with rich descriptions and dialogue."""

    return safe_generate(prompt)

# 2. üíª Code Mentor
def code_mentor(language, difficulty, topic, learning_style):
    if not all([language, topic]):
        return "‚ö†Ô∏è Please specify the programming language and topic."

    prompt = f"""Teach {language} programming at {difficulty} level.
Topic: {topic}
Learning Style: {learning_style}

Provide:
1. Clear explanation
2. Working code example
3. Step-by-step breakdown
4. Practice suggestion

Make it suitable for {difficulty} programmers with {learning_style} learning preference."""

    return safe_generate(prompt)

# 3. ‚öîÔ∏è Debate Arena
def debate_arena(topic, position, evidence_level):
    if not topic.strip():
        return "‚ö†Ô∏è Please enter a debate topic."

    prompt = f"""Debate Topic: {topic}
Position: {position}
Evidence Level: {evidence_level}

Present a structured argument with:
1. Opening statement
2. Key evidence and reasoning
3. Counter-argument awareness
4. Strong conclusion

Use {evidence_level.lower()} level evidence and reasoning."""

    return safe_generate(prompt)

# 4. üé® Creative Assistant
def creative_assistant(content_type, style, audience, topic):
    if not topic.strip():
        return "‚ö†Ô∏è Please enter a topic for content creation."

    prompt = f"""Create {content_type} content:
Topic: {topic}
Style: {style}
Audience: {audience}

Write engaging, professional content that matches the {style.lower()} style for {audience.lower()} audience."""

    return safe_generate(prompt)

# 5. üéì Learning Companion
def learning_companion(subject, learning_style, level, topic):
    if not topic.strip():
        return "‚ö†Ô∏è Please enter a specific topic to learn."

    prompt = f"""Teach {subject} at {level} level:
Topic: {topic}
Learning Style: {learning_style}

Provide:
1. Clear explanation appropriate for {level} students
2. {learning_style} learning elements
3. Practice exercise
4. Real-world application

Adapt teaching for {learning_style.lower()} learners."""

    return safe_generate(prompt)

# 6. üé≤ AI Dungeon Master
def ai_dungeon_master(setting, character_class, scenario, choice):
    if not all([scenario.strip(), choice.strip()]):
        return "‚ö†Ô∏è Please describe the scenario and your character's action."

    prompt = f"""You are a Dungeon Master. Setting: {setting}
Player Class: {character_class}
Current Scenario: {scenario}
Player Action: {choice}

Narrate what happens next with:
1. Vivid scene description
2. Consequences of the action
3. New developments
4. Options for next move

Make it immersive and engaging."""

    return safe_generate(prompt)

# 7. üí° Brainstorm Buddy
def brainstorm_buddy(problem, industry, innovation_level, constraints):
    if not problem.strip():
        return "‚ö†Ô∏è Please describe the problem you want to solve."

    prompt = f"""Business Problem: {problem}
Industry: {industry}
Innovation Level: {innovation_level}
Constraints: {constraints}

Provide creative solutions that are:
1. {innovation_level.lower()} in approach
2. Suitable for {industry}
3. Practical given constraints
4. Include implementation steps

Generate multiple innovative ideas."""

    return safe_generate(prompt)

# 8. üé≠ Personality Simulator
def personality_simulator(persona, mood, background, situation):
    if not situation.strip():
        return "‚ö†Ô∏è Please describe the situation to respond to."

    prompt = f"""Role-play as: {persona}
Current Mood: {mood}
Background: {background}
Situation: {situation}

Respond completely in character showing:
1. Unique speaking style
2. Emotional reactions
3. Personal perspective
4. Character-appropriate decisions

Stay authentic to this persona."""

    return safe_generate(prompt)

# Create the Gradio interface
def create_interface():
    # Custom CSS for better styling
    custom_css = """
    .gradio-container {
        max-width: 1200px !important;
    }
    .tab-nav button {
        font-size: 14px !important;
        padding: 8px 16px !important;
    }
    """

    with gr.Blocks(title="IBM Granite AI Multi-Tool", theme=gr.themes.Soft(), css=custom_css) as app:
        gr.Markdown("""
        # ü§ñ IBM Granite AI Multi-Tool
        ### Powered by IBM Granite 3.0 2B Instruct Model

        **8 Powerful AI Tools for Creativity, Learning & Productivity!**

        > üí° **Tip:** Fill in all required fields for best results. Processing may take 10-30 seconds.
        """)

        with gr.Tabs():
            # Story Wizard Tab
            with gr.Tab("ü™Ñ Story Wizard"):
                gr.Markdown("### Create immersive stories with customizable elements")
                with gr.Row():
                    with gr.Column(scale=1):
                        story_genre = gr.Dropdown(
                            ["Fantasy", "Sci-Fi", "Mystery", "Romance", "Horror", "Adventure", "Historical", "Comedy"],
                            label="üìö Genre", value="Fantasy"
                        )
                        story_character = gr.Textbox(
                            label="üë§ Main Character",
                            placeholder="A brave knight named Sir Galahad",
                            lines=2
                        )
                        story_setting = gr.Textbox(
                            label="üè∞ Setting",
                            placeholder="A mysterious ancient castle surrounded by enchanted forest",
                            lines=2
                        )
                        story_twist = gr.Textbox(
                            label="üåü Plot Twist",
                            placeholder="The castle is actually a spaceship from another dimension",
                            lines=2
                        )
                        story_length = gr.Radio(["Short", "Medium", "Long"], label="üìè Length", value="Medium")
                        story_btn = gr.Button("‚ú® Generate Story", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        story_output = gr.Textbox(label="üìñ Your Story", lines=25, max_lines=30)

                story_btn.click(
                    story_wizard,
                    inputs=[story_genre, story_character, story_setting, story_twist, story_length],
                    outputs=story_output
                )

            # Code Mentor Tab
            with gr.Tab("üíª Code Mentor"):
                gr.Markdown("### Learn programming with AI-powered guidance")
                with gr.Row():
                    with gr.Column(scale=1):
                        code_language = gr.Dropdown(
                            ["Python", "JavaScript", "Java", "C++", "React", "HTML/CSS", "SQL", "Go"],
                            label="üî§ Language", value="Python"
                        )
                        code_difficulty = gr.Dropdown(
                            ["Beginner", "Intermediate", "Advanced"],
                            label="üìä Level", value="Beginner"
                        )
                        code_topic = gr.Textbox(
                            label="üìù Topic",
                            placeholder="Functions and parameters",
                            lines=2
                        )
                        code_style = gr.Dropdown(
                            ["Visual", "Practical", "Analytical", "Interactive"],
                            label="üéØ Learning Style", value="Practical"
                        )
                        code_btn = gr.Button("üöÄ Get Lesson", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        code_output = gr.Textbox(label="üìö Programming Lesson", lines=25, max_lines=30)

                code_btn.click(
                    code_mentor,
                    inputs=[code_language, code_difficulty, code_topic, code_style],
                    outputs=code_output
                )

            # Debate Arena Tab
            with gr.Tab("‚öîÔ∏è Debate Arena"):
                gr.Markdown("### Practice argumentation and critical thinking")
                with gr.Row():
                    with gr.Column(scale=1):
                        debate_topic = gr.Textbox(
                            label="üéØ Debate Topic",
                            placeholder="Should artificial intelligence replace human teachers in schools?",
                            lines=3
                        )
                        debate_position = gr.Radio(
                            ["For", "Against", "Neutral Analysis"],
                            label="‚öñÔ∏è Position", value="For"
                        )
                        debate_evidence = gr.Dropdown(
                            ["Light", "Moderate", "Heavy"],
                            label="üìä Evidence Level", value="Moderate"
                        )
                        debate_btn = gr.Button("üí¨ Generate Argument", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        debate_output = gr.Textbox(label="üó£Ô∏è Debate Argument", lines=20, max_lines=25)

                debate_btn.click(
                    debate_arena,
                    inputs=[debate_topic, debate_position, debate_evidence],
                    outputs=debate_output
                )

            # Creative Assistant Tab
            with gr.Tab("üé® Creative Assistant"):
                gr.Markdown("### Professional content creation for any purpose")
                with gr.Row():
                    with gr.Column(scale=1):
                        content_type = gr.Dropdown(
                            ["Blog Post", "Marketing Copy", "Email", "Social Media Post", "Product Description", "Press Release", "Newsletter"],
                            label="üìÑ Content Type", value="Blog Post"
                        )
                        content_style = gr.Dropdown(
                            ["Professional", "Casual", "Humorous", "Academic", "Persuasive", "Inspirational"],
                            label="‚úçÔ∏è Style", value="Professional"
                        )
                        content_audience = gr.Dropdown(
                            ["General Public", "Business Professionals", "Students", "Technical Experts", "Young Adults", "Seniors"],
                            label="üë• Audience", value="General Public"
                        )
                        content_topic = gr.Textbox(
                            label="üí° Topic",
                            placeholder="The future of sustainable technology in everyday life",
                            lines=3
                        )
                        content_btn = gr.Button("‚ú® Create Content", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        content_output = gr.Textbox(label="üìù Generated Content", lines=20, max_lines=25)

                content_btn.click(
                    creative_assistant,
                    inputs=[content_type, content_style, content_audience, content_topic],
                    outputs=content_output
                )

            # Learning Companion Tab
            with gr.Tab("üéì Learning Companion"):
                gr.Markdown("### Personalized education across multiple subjects")
                with gr.Row():
                    with gr.Column(scale=1):
                        learn_subject = gr.Dropdown(
                            ["Mathematics", "Science", "History", "Literature", "Computer Science", "Business", "Psychology", "Philosophy"],
                            label="üìö Subject", value="Mathematics"
                        )
                        learn_style = gr.Dropdown(
                            ["Visual", "Practical", "Analytical", "Interactive"],
                            label="üéØ Learning Style", value="Practical"
                        )
                        learn_level = gr.Dropdown(
                            ["Elementary", "High School", "College", "Graduate"],
                            label="üéñÔ∏è Level", value="High School"
                        )
                        learn_topic = gr.Textbox(
                            label="üìñ Topic",
                            placeholder="Quadratic equations and their real-world applications",
                            lines=3
                        )
                        learn_btn = gr.Button("üéì Start Learning", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        learn_output = gr.Textbox(label="üìö Learning Material", lines=20, max_lines=25)

                learn_btn.click(
                    learning_companion,
                    inputs=[learn_subject, learn_style, learn_level, learn_topic],
                    outputs=learn_output
                )

            # AI Dungeon Master Tab
            with gr.Tab("üé≤ AI Dungeon Master"):
                gr.Markdown("### Interactive RPG storytelling and adventure")
                with gr.Row():
                    with gr.Column(scale=1):
                        rpg_setting = gr.Dropdown(
                            ["Medieval Fantasy", "Cyberpunk Future", "Post-Apocalyptic", "Space Opera", "Modern Supernatural", "Steampunk", "Ancient Mythology"],
                            label="üåç Setting", value="Medieval Fantasy"
                        )
                        rpg_class = gr.Dropdown(
                            ["Warrior", "Mage", "Rogue", "Cleric", "Ranger", "Bard", "Paladin"],
                            label="‚öîÔ∏è Class", value="Warrior"
                        )
                        rpg_scenario = gr.Textbox(
                            label="üé≠ Current Scenario",
                            placeholder="You stand before the entrance to a dark dungeon, ancient runes glowing faintly on the stone archway",
                            lines=3
                        )
                        rpg_choice = gr.Textbox(
                            label="üéØ Your Action",
                            placeholder="I carefully examine the runes for any magical traps before entering",
                            lines=3
                        )
                        rpg_btn = gr.Button("üé≤ Continue Adventure", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        rpg_output = gr.Textbox(label="üìú Adventure Continues...", lines=20, max_lines=25)

                rpg_btn.click(
                    ai_dungeon_master,
                    inputs=[rpg_setting, rpg_class, rpg_scenario, rpg_choice],
                    outputs=rpg_output
                )

            # Brainstorm Buddy Tab
            with gr.Tab("üí° Brainstorm Buddy"):
                gr.Markdown("### Innovation partner for creative problem-solving")
                with gr.Row():
                    with gr.Column(scale=1):
                        brainstorm_problem = gr.Textbox(
                            label="üéØ Problem",
                            placeholder="How to increase employee engagement in remote work environments",
                            lines=3
                        )
                        brainstorm_industry = gr.Dropdown(
                            ["Technology", "Healthcare", "Education", "Finance", "Retail", "Manufacturing", "Entertainment", "Non-Profit"],
                            label="üè¢ Industry", value="Technology"
                        )
                        brainstorm_innovation = gr.Dropdown(
                            ["Incremental", "Moderate", "Revolutionary"],
                            label="üöÄ Innovation Level", value="Moderate"
                        )
                        brainstorm_constraints = gr.Textbox(
                            label="‚ö†Ô∏è Constraints",
                            placeholder="Limited budget of $50K, 6-month timeline, team of 5 people",
                            lines=3
                        )
                        brainstorm_btn = gr.Button("üí° Generate Ideas", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        brainstorm_output = gr.Textbox(label="üß† Innovative Solutions", lines=20, max_lines=25)

                brainstorm_btn.click(
                    brainstorm_buddy,
                    inputs=[brainstorm_problem, brainstorm_industry, brainstorm_innovation, brainstorm_constraints],
                    outputs=brainstorm_output
                )

            # Personality Simulator Tab
            with gr.Tab("üé≠ Personality Simulator"):
                gr.Markdown("### Role-play different personas and perspectives")
                with gr.Row():
                    with gr.Column(scale=1):
                        persona_type = gr.Dropdown([
                            "Optimistic Entrepreneur", "Skeptical Scientist", "Artistic Dreamer", "Practical Engineer",
                            "Wise Philosopher", "Energetic Teacher", "Cautious Analyst", "Bold Explorer",
                            "Compassionate Counselor", "Strategic Leader"
                        ], label="üé≠ Persona", value="Optimistic Entrepreneur")

                        persona_mood = gr.Dropdown([
                            "Excited", "Thoughtful", "Confident", "Curious", "Determined",
                            "Relaxed", "Focused", "Enthusiastic", "Contemplative"
                        ], label="üòä Mood", value="Confident")

                        persona_background = gr.Textbox(
                            label="üìö Background",
                            placeholder="Recently launched a successful startup and is now mentoring young entrepreneurs",
                            lines=3
                        )
                        persona_situation = gr.Textbox(
                            label="üé¨ Situation",
                            placeholder="A young person asks for advice about whether to quit their stable job to pursue their passion",
                            lines=3
                        )
                        persona_btn = gr.Button("üé≠ Simulate Response", variant="primary", size="lg")

                    with gr.Column(scale=2):
                        persona_output = gr.Textbox(label="üí¨ Character Response", lines=20, max_lines=25)

                persona_btn.click(
                    personality_simulator,
                    inputs=[persona_type, persona_mood, persona_background, persona_situation],
                    outputs=persona_output
                )

        # Footer with status
        gr.Markdown(f"""
        ---
        **üöÄ Status:** {"‚úÖ Model loaded and ready!" if ai.model is not None else "‚ùå Model loading failed"}
        **üîß Model:** {ai.model_name}
        **üí° Tip:** For best results, be specific and detailed in your inputs!

        *Powered by IBM Granite AI - Experience open-source AI across 8 creative applications!* üåü
        """)

    return app

# Launch the application
if __name__ == "__main__":
    print("üöÄ Starting IBM Granite AI Multi-Tool Application...")

    # Check if model loaded successfully
    if ai.model is None:
        print("‚ùå Model failed to load. Please check your internet connection and try again.")
        print("üí° You may need to restart the runtime and run the cell again.")
    else:
        print("‚úÖ System ready! Launching interface...")

    # Create and launch the app
    app = create_interface()
    app.launch(
        share=True,  # Creates a public shareable link
        server_name="0.0.0.0",  # Makes it accessible in Colab
        server_port=7860,
        show_error=True,
        quiet=False
    )

    print("üéâ Application is now running!")
    print("üì± Use the public link above to share with others!")

